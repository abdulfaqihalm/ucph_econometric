---
title: "assignment7"
author: "Abdullah Faqih Al Mubarok"
format: html
editor: visual
---

```{r}
#| warning: false
library(wooldridge)
library(tidyverse)
library(stargazer)
library(lmtest)
library(car)
library(sandwich)
softdrink_data <- get(load("softdrink.RData"))
wage1_data <- wage1
hprice1_data <- hprice1
vote1_data <- vote1
```

## Problem 7.1: Obesity rates (continued)

::: callout-caution
Please note that this is a continuation of Problem 6.1 from yesterday's exercises. I've provided my answers for the first ten exercises. You should continue with exercises 7.1.11-7.1.18.
:::

Data from OECD shows that the rate of obesity in Denmark reached $13.5\%$ in 2010. This corresponds to an increase of approximately $18\%$ compared to 2005 and a $150\%$ rise since 1987. This places Denmark below the average level in OECD countries but above the level for comparable countries like Sweden and Norway. The rise in obesity seems to be larger among younger and less educated individuals.

Even though obesity, to a large extent, is thought to be the outcome of an individual decision process, politicians must also consider the impact of these private decisions on society. Extreme obesity is correlated with many lifestyle-related illnesses, and it, therefore, poses a large burden on healthcare systems. More importantly, it impacts society in countries with publicly financed healthcare systems (like Denmark) since obese individuals pay the same to the healthcare system as non-obese individuals that do not have the same healthcare needs. Politicians, therefore, have a direct interest in reducing obesity. Several lifestyle factors seem to have contributed to the obesity epidemic during the last decades: The price of food, especially unhealthy foods, has declined, the amount of sedentary work has increased, and the use of electrical equipment and private cars has expanded.

The political system is searching for ways to reduce the problem. One way to do this is to consider using economic instruments to change people's lifestyles and reduce, e.g., the consumption of unhealthy foods like soft drinks. The increasing consumption of soft drinks is an essential cause of the increased prevalence of obesity. In this assignment, you will investigate the lifestyle behavior of different household groups regarding soft drink consumption and the potential for politicians to change this behavior by imposing economic (tax) instruments.

### Data description

The data set is called `softdrink.RData` and is available [here](https://absalon.ku.dk/courses/57563/files/6209254?module_item_id=1712482). It is a subset of a larger data set from the research company GfK ConsumerTracking Scandinavia which covers approximately 2500 consumers that, every week, report their purchase of everyday staples like food for in-house consumption. The respondents select themselves into the panel. The purchases are registered by the household member who is mainly responsible for shopping. The data set covers aggregate food and soft drink expenditures in 2004. The data set also includes household characteristics aggregated into monthly observations. That is, each observation of purchases is from a select week. The data set contains the following variables:

| Variable      | Description                                                   |
|-----------------|-------------------------------------------------------|
| `volpers`     | volume of soda per person in household                        |
| `soft`        | $=1$ if soda has been bought in a given month, 0 otherwise    |
| `price`       | average price paid for soda in a month                        |
| `totfoodpers` | total food expenditure per person                             |
| `age`         | age in years for the primary shopper                          |
| `single`      | $=1$ if the household consists of a single adult, 0 otherwise |
| `capital`     | $=1$ if households lives in capital area, 0 otherwise         |
| `urban`       | $=1$ if households lives in urban area, 0 otherwise           |
| `rural`       | $=1$ if households lives in rural area, 0 otherwise           |
| `high_edu`    | $=1$ if primary shopper has a higher education, 0 otherwise   |
| `kid06`       | $=1$ if there are kids between 0 and 6, 0 otherwise           |
| `kid714`      | $=1$ if there are kids between 7 and 14, 0 otherwise          |
| `kid1520`     | $=1$ if there are kids between 15 and 20, 0 otherwise         |

::: callout-important
Start by loading the data set. Note that the environment is called `students` and not `data.` Therefore, I changed the name in the following code snippet:

```{r}
load("softdrink.RData")
data <- students
```
:::

### Exercises

Please answer the following questions:

1.  Provide a table with all the variables in the data set. What type of data are we working with? Explain.

::: {.callout-note appearance="simple" collapse="true"}
## Solution

The included data set includes all of the following:

```{r}
#| message: false
library(stargazer)
stargazer(data,
    type = "text",
    summary.logical = FALSE,
    omit.summary.stat = c("p25", "p75")
)
```

We are working with a cross-sectional data set.

::: callout-warning
In an exam situation, I would expect you to provide details of what can be read from the table. The above would not be sufficient for a passing grade. Some things to consider:

1.  What can we read from the table of descriptive statistics?
2.  Is there anything that immediately springs to mind?
3.  What variables are we working with?
4.  Can we already now infer anything interesting about the problem at hand?\*
:::
:::

2.  What do you think are the main sources of errors in this type of data in relation to soft drink consumption? For instance, what problems may arise as a result of self-selection? Discuss.

::: {.callout-note appearance="simple" collapse="true"}
## Solution

The primary source of error is probably related to households selecting themselves into the panel. This reduces external validity, as we cannot document that the panelists were found by random sampling. For instance, one could imagine that people that want to invest time in documenting their purchasing behavior are probably more likely to also be attentive to their consumption.

Another issue is related to the fact that the data is only on within-household purchases. This implies that consumption outside the household is not necessarily taken into account. Additionally, one could imagine that the purchasing and consumption of soda is something you are relatively more inclined to try hiding, in comparison to fruits or vegetables, for instance. This could lead to possible under-reporting of particular unhealthy habits. This would not be a problem if the under-reporting was random across all groups, but it may be so if it is specific to the consumption of certain food commodities.

We do not know anything about the distribution within the household. Therefore, the consumption of soda is treated as a simple average across all individuals in the partaking household. If we were to consider a household with two adults and one child, where the child is the only consumer of soft drinks, the per-person consumption may not appear that large, even though the child may be drinking excessive amounts of soda.
:::

3.  Draw and present a histogram of the age distribution for the main shopping responsible. Do you think it is representative of the Danish population?

::: {.callout-note appearance="simple" collapse="true"}
## Solution

```{r}
library(ggplot2)
ggplot(data, aes(x = age)) +
    geom_histogram(aes(y = after_stat(density)), colour = "black", fill = "brown1", alpha = 0.5, bins = 20) +
    geom_density(fill = "steelblue4", alpha = 0.5) +
    labs(x = "Age", y = "Density", title = "The distribution of age among our sample") +
    theme_minimal()
```

When considering that we are not including persons with $age < 18$, the distribution is somewhat more reasonable. Nevertheless, we still note that the average age appears to be much larger than we would expect. This could be a slight indication of selection bias.
:::

4.  Calculate the mean consumption for singles with $age<35$, singles between 35 and 50, singles between 50 and 70, and singles above 70, and the same for couples (in total, eight different conditional sample means).

::: {.callout-note appearance="simple" collapse="true"}
## Solution

We calculate the conditional means using:

```{r}
mean(data$volpers[data$age < 35 & data$single == 1])
mean(data$volpers[35 < data$age & data$age < 50 & data$single == 1])
```

$\vdots$

```{r}
mean(data$volpers[70 < data$age & data$single == 0])
```
:::

5.  Who are the largest consumers of soft drinks? Is this what you expected?

::: {.callout-note appearance="simple" collapse="true"}
## Solution

It would seem that single persons consume more soda than non-singles. In addition, younger people tend to be consuming relatively more. Given the introduction, this follows our initial expectations. We should note that the fact that singles drink more soda could relate to the problem we discussed initially. A simple average is a poor description of the actual consumption within a given household. This is not the case for singles, as we would assume their purchases go towards their own consumption (at least primarily).
:::

6.  Calculate the frequency of zero purchases of soft drinks in each of the eight groups and comment on the results in relation to question 3. (Remember that the variable `soft` is a dummy indicating whether the household purchased soft drinks or not in a given month).

::: {.callout-note appearance="simple" collapse="true"}
## Solution

I calculate the conditional means as:

```{r}
1 - mean(data$soft[data$age < 35 & data$single == 1])
1 - mean(data$soft[35 < data$age & data$age < 50 & data$single == 1])
```

$\vdots$

```{r}
1 - mean(data$soft[70 < data$age & data$single == 0])
```

When inspecting the last column of our table, we find that singles, more so than non-singles, purchase no soda at all. The same goes for the different age groups, where higher age seems to imply a higher frequency of zero purchases. This could indicate that singles who consume soda do so in relatively large quantities.
:::

7.  Now remove all observations that have not purchased any soda. As we assume that the consumption of soft drinks in liters per person is to some extent determined by the price, the age and education of the household member who is mainly responsible for shopping, how much the household spends on food per person, the number of kids in the household, urbanity, and single status, we assume the following model for the population: \begin{align*}
     \log(volpers)&=\beta_0 + \beta_1\log(price) + \beta_2age + \beta_3 age^2 + \beta_4 kid06 + \beta_5 kid714 \\ &+ \beta_6 kid1520 + \beta_7capital + \beta_8 urban + \beta_9 single + \beta_{10} \log(totfoodpers) + u.
    \end{align*} Estimate the model and report your results in equation form, with corresponding standard errors, the number of observations, and $R^2$.

::: {.callout-note appearance="simple" collapse="true"}
## Solution

We estimate our model:

```{r}
# Estimation
data <- subset(softdrink_data, volpers > 0)
logModel <- lm(log(volpers) ~ log(price) + age + I(age^2) +
    kid06 + kid714 + kid1520 +
    capital + urban + single +
    log(totfoodpers), data = data)

# Results
stargazer(logModel,
    type = "text",
    title = "Wage differences",
    omit.stat = c("ser", "f", "adj.rsq"),
    intercept.bottom = FALSE,
    star.cutoffs = c(0.05, 0.01, 0.001)
)
```
:::

8.  Which assumptions do we need to invoke to ensure the unbiasedness of our OLS estimates? Explain.

::: {.callout-note appearance="simple" collapse="true"}
## Solution

Unbiasedness ($E(\hat{\beta}_j) = \beta_j$) is ensured under Assumptions MLR. 1 through MLR. 4. Consistency ($\hat{\beta}_j \rightarrow \beta_j$ as $n\rightarrow \infty$) is implied by Assumptions MLR. 1 through MLR. 3 and the weaker MLR. 4': \begin{align}
        E(u) = 0 \quad \text{and} \quad Cov(x_j, u) = 0.
\end{align} The latter ensures linear independence, whilst MLR. 4 ensures complete independence. Consistency is, therefore, a weaker property of our estimator than unbiasedness.

::: callout-warning
In an exam situation, I would methodically present and discuss the implications of each assumption formally.
:::
:::

9.  Which assumptions need to hold in order to carry out standard inference ($t$-tests and $F$-tests)? Why?

::: {.callout-note appearance="simple" collapse="true"}
## Solution

Ideally, we would like the population error term to be independent of the explanatory variables and normally distributed with mean zero and variance $\sigma^2$, as surmised by Assumption MLR. 6: $u\sim \mathcal{N}(0, \sigma^2)$. Seeing as this is the strongest assumption we have imposed (by far), we can replace this with the weaker MLR. 5 of conditional homoskedasticity: \begin{align}
        Var(u \mid x_1, x_2, \dotsc, x_k) = \sigma^2,
\end{align} as this for large enough samples (and if a Central Limit Theorem (CLT) applies) ensures that our $t$- and $F$-statistics are asymptotically normally distributed. If this is not the case, we cannot carry out standard inference. If heteroskedasticity is persistent, you should use heteroskedasticity-robust standard errors for inference, but these are only valid in sufficiently large samples.

::: callout-warning
In an exam situation, I would expect you to spend more time discussing the implications of assuming asymptotic normality. I **do not** expect you to provide proof of a CLT applying, but you should, at minimum, note that this is a requirement for assuming asymptotic normality.
:::
:::

10. Do these assumptions seem reasonable in our model? Reflect on your answer.

::: {.callout-note appearance="simple" collapse="true"}
## Solution

**Important problems to note:**

-   **MLR.2**: We clearly do not have a random sampling. Instead, you could discuss whether participating in the panel is independent of your day-to-day consumption of soda (or other ways to circumvent this issue).
-   **MLR.4**: You can always discuss the validity of assuming a zero conditional mean. In practice, we would never expect it to be fulfilled entirely. Therefore, a *good discussion* relates to the data at hand. Is there anything obvious we are missing here that may be important? We can always come up with the argument that it would be convenient to have more (and better) available data, but what would be *essential* for the validity of your study.
-   For both **MLR.5** and **MLR. 6**, we should investigate further as we have specific formal tests or graphical tools that will allow for a better and more thorough discussion.

**Less important:**

-   **MLR.3** Either you have perfect collinearity, or you don't. If this is an issue, you have a fundamental and critical issue, which means you cannot estimate your parameters with OLS. Fix it!
-   **MLR.1** This is a design question. You are assuming some relationship in the population. Given that the proposed model is linear in its parameters, we have no issues. What you instead could do, is discuss whether the functional form of the proposed model seems valid.
:::

11. Plot the density of $volpers$ and $\log(volpers)$. Based on the two figures, and your general knowledge, discuss what the difference is of using $\log(volpers)$ as the dependent variable rather than $volpers$.

    ```{r}
    volper_dist <- softdrink_data |> filter(soft!=0) |>  mutate("log(volpers)" = log(volpers)) |>  select(c("volpers", "log(volpers)")) |> pivot_longer(cols = everything(), names_to = "colname", values_to = "value")

    ggplot(data = volper_dist, mapping = aes(x = value, fill = colname, color = colname)) + 
      geom_density(alpha = 0.5, bw = 0.05) + 
      facet_grid(cols = vars(colname), scales = "free") + 
      labs(title = "volpers and log(volpers) density", 
           fill = "value", color = "value") + 
      theme_bw()
    ```

    From the plot above, we can see that the log() transformation of volpers makes the data distribution closer to the normal distribution which satisfies CLM assumption. In addition it also narrows the range into \[-5.0,2.5\] instead of \[0,15\].

12. Assume that the Classical Linear Model (CLM) assumptions apply. Estimate the proposed model for the population and report your findings in a table. Discuss your results. Are they as you expected?

    The model was already calculated on the 7th question.

13. Calculate a confidence interval for the parameter on single status (`single`). How does this compare to your previous results about the significance of this parameter?

    ```{r}
    critical_point <- qt(p = 0.001, df = 13856, lower.tail = FALSE)
    lower_bound_single = round(0.154 - (critical_point*0.018),3)
    upper_bound_single = round(0.154 + (critical_point*0.018),3)

    paste0("lower bound: ", lower_bound_single, "  upper bound: ", upper_bound_single)


    ```

    Since we are the single parameter is significance even at 1% level, we calculated the confidence interval for it with 99% confidence interval. Thus, from the above calculation, the value of single parameter would lie on (0.098,0.21) for 99% of the samples. It is consistent since the range does not contain zero.

14. Test for the joint significance of urbanity (the variables $urban$ and $capital$). Remember to state $H_0$ and $H_1$ when testing.

    To do that, we will use restricted F-test where the restricted model is the one without urban and capital variables. The hypothesis is:

    \begin{align*}
     H_{0} : \beta_{urban} = \beta_{capita} = 0 \\  H_{1} : \beta_{urban} = 0 or \beta_{capita} = 0
    \end{align*} \
    In addition, we set the significance level 5%.

    ```{r}
    data <- subset(softdrink_data, volpers > 0)
    logModel_rest <- lm(log(volpers) ~ log(price) + age + I(age^2) +
        kid06 + kid714 + kid1520 + single +
        log(totfoodpers), data = data)

    anova(logModel, logModel_rest)
    anova(logModel_rest, logModel)

    ```

    From the restricted F-test above, we can see that the p-values is lesser than our threshold (5%). It is also significance at 1% level. Thus, we can confidently reject the null hypothesis. In conclusion, we can confidently say that either marginal effect of $urban$ or $capital$ is not zero and choose to keep the two variables on our model.

15. Calculate the partial effects of having children of different ages (i.e. $kid06$, $kid714$, and $kid1520$). Interpret.

    The partial effect for having those three groups of children can be calculated, assuming other factors are held fix, by summing each marginal effect of each children age group. Therefore we have (-0.231 - 0.280 - 0.165)\*100 = -67.6%.

## Problem 7.2

Use the data in `wage1` for this exercise.

1.  Using the following hourly wage equation: \begin{align*}
         \widehat{\log(wage)} &=\underset{(.119)}{.389} - \underset{(.168)}{.227}female + \underset{(.008)}{.082} educ \\
         &- \underset{(.0131)}{.0056}female\cdot educ + \underset{(.005)}{.029}exper - \underset{(.00011)}{.00058}exper^2 \\
         &+ \underset{(.007)}{.032}tenure + \underset{(.00024)}{.00059}tenure^2 \\
         n&=526, \quad R^2 = .441
    \end{align*} Estimate the gender differential in hourly wage when $educ = 12.5$. Compare this with the estimated differential when $educ = 0$.

    To calculate the difference in gender, the difference between the two is :

    \begin{align*}
         diff = -0.227 - 0.0056educ
    \end{align*}

    where $educ = 12.5$, we have:

    \begin{align*}
         \%\Delta_{wage} = -0.227  - (0.0056*12.5) \\      = -0.297 = -29.7%
    \end{align*}

    where $educ = 0$, we have:

    \begin{align*}
         \%\Delta_{wage} = -0.227 = -22.7% 
    \end{align*}

    From the calculation above we can see that the additional 12.5 years of education adding the difference of -7%.

2.  Run the regression used to obtain the above estimation, but with $female\cdot (educ-12.5)$ replacing $female\cdot educ$. How do you interpret the coefficient on $female$ now?

    ```{r}
    wage1_model2 <- lm(data = wage1_data, 
                      formula = log(wage) ~ female + educ + 
                        I(female*(educ-12.5)) + exper + I(exper^2) + 
                        tenure + I(tenure^2))

    stargazer(wage1_model2,
        type = "text",
        title = "Wage differences with female.(educ-12.5)"
    )

    paste0("Mean of education: ", mean(wage1_data$educ))

    ```

    From the above regression result, the marginal interaction effect of gender on the education average (assuming 12.5 is the average of education, which is true). In conclusion, the gender difference of being female has partial interaction on education average about -0.6%. Then, for female, where we have educ = 12.5, we will have effect of (-0.296 + -0.006\*(educ-12.5) ) = -0.296 = -29.6% which is the same as the above difference.

3.  Is the coefficient on $female$ in part 1 statistically significant? Compare this with the hourly wage equation from 1 and comment.

    From the above part 1 the significant level can be calculated (assuming homoskedasticity) where we have $H_{0}: \beta _{female} = 0$(two-sided test) :

    ```{r}
    t_statistic <- (-0.227 - 0 )/0.0131
    t_test_result <- 2*pt(q = -abs(t_statistic), df = (526-7-1), lower.tail = TRUE)
    paste0("T-test result: ", t_test_result)
    ```

    From the result above, we can see that the female coefficient in part 1 is also statistically significant even at 1% significant level. This is also true for the part 2 female coefficient which is also statistically significant even at the same significant level. In conclusion,

## Problem 7.3

1.  Use the data in `hprice1` to obtain the heteroskedasticity-robust standard errors for equation (8.17). Discuss any important differences with the usual standard errors.

    To do that, we fit 8.17 population model and use the coeftest from lmtest and car package.

    ```{r}
    hprice1_model <- lm(data = hprice1_data, 
                        formula <- price ~ lotsize + sqrft + bdrms)

    ggplot(data = data.frame(u = residuals(hprice1_model), fit = fitted(hprice1_model)), 
           mapping = (aes(x = fit, y = u ))) + 
      geom_point() + 
      geom_line(y = 0) + 
      labs(title = "E(u_hat | y_hat) distribution")
      theme_bw()

    # Calculate robust se's
    cov1 = vcovHC(hprice1_model, type = "HC1")
    robust_se = sqrt(diag(cov1))


    coeftest(hprice1_model, vcov = hccm)
    ```

    As we see from the result above, the heteroskedasticity-robust standard error tends to have larger value. This makes sense since if heteroskedasticity is there on the data, we are having stricter requirement on our estimation. This implies that we are having lesser significant variable which is only the sqrft at 1% level.

2.  Repeat part 1 for equation (8.18).

    ```{r}
    hprice1_model2 <- lm(data = hprice1_data, 
                        formula <- log(price) ~ log(lotsize) + log(sqrft) + bdrms)

    ggplot(data = data.frame(u = residuals(hprice1_model2), fit = fitted(hprice1_model)), 
           mapping = (aes(x = fit, y = u ))) + 
      geom_point() + 
      geom_line(y = 0) + 
      labs(title = "E(u_hat | y_hat) distribution of log() model")
      theme_bw()

    # Calculate robust se's
    cov1 = vcovHC(hprice1_model2, type = "HC1")
    robust_se = sqrt(diag(cov1))

    stargazer(hprice1_model2, hprice1_model2, 
              type = "text",
              se = list(NULL, robust_se), # setting to robust se
              title = "The wage equation",
              omit.stat = c("ser", "F", "adj.rsq"),
              intercept.bottom = FALSE,
              dep.var.labels.include = FALSE
              )
    ```

3.  What does this example suggest about heteroskedasticity and the transformation used for the dependent variable?

    Those two fitted model above tells use that having log() transformation will make our variance is not as extreme as before hence making our estimated residuals closer to normal. It is reflected from certainty of our estimations which were greater on the log() transformed model.

## Problem 7.4

Use `vote1` for this exercise.

1.  Estimate a model with $voteA$ as the dependent variable and $prtystrA$, $democA$, $\log(expendA)$, and $\log(expendB)$ as independent variables. Obtain the OLS residuals, $\hat{u}_i$, and regress these on all of the independent variables. Explain why you obtain $R^2=0$.

    ```{r}
    vote1_model <- lm(data = vote1_data, 
                      formula = voteA ~ prtystrA + democA + lexpendA + lexpendB)

    u_hat_data <- vote1_data |> 
      select(prtystrA, democA, lexpendA, lexpendB) |> 
      mutate(u_hat = residuals(vote1_model))

    u_hat_model <- lm(data = u_hat_data, 
                      formula = u_hat ~ prtystrA + democA + lexpendA + lexpendB)

    summary(u_hat_model)

    paste0("Near zero u_hat (<1): ", length(u_hat_data[u_hat_data$u_hat<1,]$u_hat))

    ggplot(data = u_hat_data, mapping = aes(x = u_hat)) + 
      geom_density()
    ```

    From the result above, the near zero R-square tells us that our regress model u on x is not better than a horizontal line due to the estimated u is not correlated with all of the explanatory variables. This is also indicated from the summary of regression of u on x where all of the estimated coefficient are not significant

2.  Now, compute the Breusch-Pagan test for heteroskedasticity. Use the $F$ statistic version and report the $p$-value.

    ```{r}
    u_hat_model_bp <- lm(data = u_hat_data, 
                      formula = u_hat^2 ~ prtystrA + democA + lexpendA + lexpendB)

    u_hat_model_bp_summary <- summary(u_hat_model_bp)

    f_test_result <- pf(q=u_hat_model_bp_summary$fstatistic[1], 4, 168, lower.tail = FALSE)

    stargazer(u_hat_model_bp, 
              type = "text",
              title = "The Breusch-Pagan test",
              intercept.bottom = FALSE,
              star.cutoffs = c(0.05, 0.01, 0.001))

    paste0("P-value of F-statistic: ", f_test_result)
    ```

    The bp test can be done by regressing u_hat_square on our explanatory variables. From the result above we have a f-statistic of 2.33 which has p-value of 0.058 which is just larger at 5% significant level. From the estimated coefficient we can also see that several coefficient are statistically significant. It might be that we have heteroskedasticity, but we are not very sure of it.

3.  Compute the special case of the White test for heteroskedasticity, again using the $F$ statistic form. How strong is the evidence for heteroskedasticity now?

    ```{r}
    u_hat_model_white <- lm(data = u_hat_data, 
                      formula = I(u_hat^2) ~ vote1_model$fit + I(vote1_model$fit^2))

    u_hat_model_white_summary <- summary(u_hat_model_white)

    stargazer(u_hat_model_white, 
              type = "text",
              title = "The Breusch-Pagan test",
              intercept.bottom = FALSE,
              star.cutoffs = c(0.05, 0.01, 0.001))

    f_test_result <- pf(q=u_hat_model_white_summary$fstatistic[1], 2, 170, lower.tail = FALSE)
    paste0("P-value of F-statistic: ", f_test_result)
    ```

    Here, from the white test, we can see that we also have larger p-value compared to our threshold (0.05) and also slightly larger than BP calculation. However, we are still not pretty confident to accept the null.
